{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYgoY5hFv5SL",
        "outputId": "a70c8f9c-cbb6-4baa-ccc2-9774b8c75a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'"
      ],
      "metadata": {
        "id": "8ljZdDoJv_gR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d balaka18/email-spam-classification-dataset-csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYPqnVDZwZrP",
        "outputId": "10449055-3d54-4013-e263-aab660971160"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading email-spam-classification-dataset-csv.zip to /content\n",
            "100% 1.66M/1.66M [00:01<00:00, 1.41MB/s]\n",
            "100% 1.66M/1.66M [00:01<00:00, 1.26MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip email-spam-classification-dataset-csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TTv83H0wcAq",
        "outputId": "afa384a4-9048-4043-f658-e1a960b9dee9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  email-spam-classification-dataset-csv.zip\n",
            "  inflating: emails.csv              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "F16u1WUEwvgj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('emails.csv')"
      ],
      "metadata": {
        "id": "s8V6z62HxaQn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "vizdpJ9AxvEc",
        "outputId": "feac36e5-8cdc-47ac-8b38-25ddcb241980"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  \\\n",
              "0        Email 1    0   0    1    0    0   0    2    0    0  ...         0   \n",
              "1        Email 2    8  13   24    6    6   2  102    1   27  ...         0   \n",
              "2        Email 3    0   0    1    0    0   0    8    0    0  ...         0   \n",
              "3        Email 4    0   5   22    0    5   1   51    2   10  ...         0   \n",
              "4        Email 5    7   6   17    1    5   2   57    0    9  ...         0   \n",
              "...          ...  ...  ..  ...  ...  ...  ..  ...  ...  ...  ...       ...   \n",
              "5167  Email 5168    2   2    2    3    0   0   32    0    0  ...         0   \n",
              "5168  Email 5169   35  27   11    2    6   5  151    4    3  ...         0   \n",
              "5169  Email 5170    0   0    1    1    0   0   11    0    0  ...         0   \n",
              "5170  Email 5171    2   7    1    0    2   1   28    2    0  ...         0   \n",
              "5171  Email 5172   22  24    5    1    6   5  148    8    2  ...         0   \n",
              "\n",
              "      jay  valued  lay  infrastructure  military  allowing  ff  dry  \\\n",
              "0       0       0    0               0         0         0   0    0   \n",
              "1       0       0    0               0         0         0   1    0   \n",
              "2       0       0    0               0         0         0   0    0   \n",
              "3       0       0    0               0         0         0   0    0   \n",
              "4       0       0    0               0         0         0   1    0   \n",
              "...   ...     ...  ...             ...       ...       ...  ..  ...   \n",
              "5167    0       0    0               0         0         0   0    0   \n",
              "5168    0       0    0               0         0         0   1    0   \n",
              "5169    0       0    0               0         0         0   0    0   \n",
              "5170    0       0    0               0         0         0   1    0   \n",
              "5171    0       0    0               0         0         0   0    0   \n",
              "\n",
              "      Prediction  \n",
              "0              0  \n",
              "1              0  \n",
              "2              0  \n",
              "3              0  \n",
              "4              0  \n",
              "...          ...  \n",
              "5167           0  \n",
              "5168           0  \n",
              "5169           1  \n",
              "5170           1  \n",
              "5171           0  \n",
              "\n",
              "[5172 rows x 3002 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ef0cc17-e727-48ae-9932-ada71dac8b2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email No.</th>\n",
              "      <th>the</th>\n",
              "      <th>to</th>\n",
              "      <th>ect</th>\n",
              "      <th>and</th>\n",
              "      <th>for</th>\n",
              "      <th>of</th>\n",
              "      <th>a</th>\n",
              "      <th>you</th>\n",
              "      <th>hou</th>\n",
              "      <th>...</th>\n",
              "      <th>connevey</th>\n",
              "      <th>jay</th>\n",
              "      <th>valued</th>\n",
              "      <th>lay</th>\n",
              "      <th>infrastructure</th>\n",
              "      <th>military</th>\n",
              "      <th>allowing</th>\n",
              "      <th>ff</th>\n",
              "      <th>dry</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Email 1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Email 2</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>102</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Email 3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Email 4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Email 5</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>Email 5168</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5168</th>\n",
              "      <td>Email 5169</td>\n",
              "      <td>35</td>\n",
              "      <td>27</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>151</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5169</th>\n",
              "      <td>Email 5170</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5170</th>\n",
              "      <td>Email 5171</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5171</th>\n",
              "      <td>Email 5172</td>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>148</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5172 rows × 3002 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ef0cc17-e727-48ae-9932-ada71dac8b2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ef0cc17-e727-48ae-9932-ada71dac8b2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ef0cc17-e727-48ae-9932-ada71dac8b2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('Email No.', axis=1)"
      ],
      "metadata": {
        "id": "Cl2pe3pfxwK4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_TzRjwI06d_",
        "outputId": "1215ec87-b8f0-42cb-efb9-65375b09ad0b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "the           0\n",
              "to            0\n",
              "ect           0\n",
              "and           0\n",
              "for           0\n",
              "             ..\n",
              "military      0\n",
              "allowing      0\n",
              "ff            0\n",
              "dry           0\n",
              "Prediction    0\n",
              "Length: 3001, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Z7dzkb0c0_6n",
        "outputId": "80020359-9683-4a7d-8d11-af7ea784825d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 the        to       ect       and       for        of  \\\n",
              "the         1.000000  0.852715  0.337249  0.841200  0.784112  0.796397   \n",
              "to          0.852715  1.000000  0.375480  0.825474  0.781971  0.752722   \n",
              "ect         0.337249  0.375480  1.000000  0.272863  0.369777  0.178028   \n",
              "and         0.841200  0.825474  0.272863  1.000000  0.751287  0.809665   \n",
              "for         0.784112  0.781971  0.369777  0.751287  1.000000  0.681457   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "military    0.129466  0.091639 -0.007690  0.084147  0.067151  0.073004   \n",
              "allowing    0.127019  0.120059  0.004368  0.124766  0.121057  0.108786   \n",
              "ff          0.341878  0.406666  0.141460  0.400225  0.301074  0.444252   \n",
              "dry         0.051021  0.071388  0.002492  0.042484  0.038126  0.026403   \n",
              "Prediction -0.004421  0.055277 -0.120782  0.114364 -0.003101  0.197234   \n",
              "\n",
              "                   a       you       hou        in  ...  connevey       jay  \\\n",
              "the         0.784451  0.471392  0.303621  0.845670  ...  0.008926  0.075479   \n",
              "to          0.896466  0.508513  0.347993  0.881759  ...  0.013250  0.101247   \n",
              "ect         0.400009  0.155783  0.974152  0.298387  ...  0.134339  0.031431   \n",
              "and         0.815196  0.476764  0.235953  0.874276  ...  0.005151  0.104454   \n",
              "for         0.744098  0.495852  0.329051  0.762659  ...  0.022168  0.041775   \n",
              "...              ...       ...       ...       ...  ...       ...       ...   \n",
              "military    0.111685  0.006498  0.005429  0.120620  ... -0.002249 -0.002979   \n",
              "allowing    0.105358  0.082757 -0.000966  0.138099  ... -0.002675 -0.003543   \n",
              "ff          0.464473  0.195058  0.114210  0.448303  ...  0.005403  0.073690   \n",
              "dry         0.093822  0.028883  0.000601  0.077751  ... -0.003373  0.035028   \n",
              "Prediction  0.107776  0.130293 -0.128340  0.154055  ... -0.030375 -0.031694   \n",
              "\n",
              "              valued       lay  infrastructure  military  allowing        ff  \\\n",
              "the         0.225586  0.223426        0.101768  0.129466  0.127019  0.341878   \n",
              "to          0.232847  0.255793        0.093322  0.091639  0.120059  0.406666   \n",
              "ect         0.046080  0.061550        0.004393 -0.007690  0.004368  0.141460   \n",
              "and         0.272963  0.253440        0.151980  0.084147  0.124766  0.400225   \n",
              "for         0.236213  0.213631        0.134469  0.067151  0.121057  0.301074   \n",
              "...              ...       ...             ...       ...       ...       ...   \n",
              "military    0.043408  0.104297        0.041300  1.000000  0.055227  0.049524   \n",
              "allowing   -0.005130  0.018550        0.276001  0.055227  1.000000  0.096212   \n",
              "ff          0.130356  0.164296        0.114092  0.049524  0.096212  1.000000   \n",
              "dry        -0.006468  0.018939       -0.003137  0.010835 -0.003995  0.049690   \n",
              "Prediction  0.098775  0.064315        0.038161  0.064850  0.011279  0.135479   \n",
              "\n",
              "                 dry  Prediction  \n",
              "the         0.051021   -0.004421  \n",
              "to          0.071388    0.055277  \n",
              "ect         0.002492   -0.120782  \n",
              "and         0.042484    0.114364  \n",
              "for         0.038126   -0.003101  \n",
              "...              ...         ...  \n",
              "military    0.010835    0.064850  \n",
              "allowing   -0.003995    0.011279  \n",
              "ff          0.049690    0.135479  \n",
              "dry         1.000000   -0.006260  \n",
              "Prediction -0.006260    1.000000  \n",
              "\n",
              "[3001 rows x 3001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5494d683-52ca-4815-ab12-6dca3fb93d10\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>the</th>\n",
              "      <th>to</th>\n",
              "      <th>ect</th>\n",
              "      <th>and</th>\n",
              "      <th>for</th>\n",
              "      <th>of</th>\n",
              "      <th>a</th>\n",
              "      <th>you</th>\n",
              "      <th>hou</th>\n",
              "      <th>in</th>\n",
              "      <th>...</th>\n",
              "      <th>connevey</th>\n",
              "      <th>jay</th>\n",
              "      <th>valued</th>\n",
              "      <th>lay</th>\n",
              "      <th>infrastructure</th>\n",
              "      <th>military</th>\n",
              "      <th>allowing</th>\n",
              "      <th>ff</th>\n",
              "      <th>dry</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.852715</td>\n",
              "      <td>0.337249</td>\n",
              "      <td>0.841200</td>\n",
              "      <td>0.784112</td>\n",
              "      <td>0.796397</td>\n",
              "      <td>0.784451</td>\n",
              "      <td>0.471392</td>\n",
              "      <td>0.303621</td>\n",
              "      <td>0.845670</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008926</td>\n",
              "      <td>0.075479</td>\n",
              "      <td>0.225586</td>\n",
              "      <td>0.223426</td>\n",
              "      <td>0.101768</td>\n",
              "      <td>0.129466</td>\n",
              "      <td>0.127019</td>\n",
              "      <td>0.341878</td>\n",
              "      <td>0.051021</td>\n",
              "      <td>-0.004421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.852715</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375480</td>\n",
              "      <td>0.825474</td>\n",
              "      <td>0.781971</td>\n",
              "      <td>0.752722</td>\n",
              "      <td>0.896466</td>\n",
              "      <td>0.508513</td>\n",
              "      <td>0.347993</td>\n",
              "      <td>0.881759</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013250</td>\n",
              "      <td>0.101247</td>\n",
              "      <td>0.232847</td>\n",
              "      <td>0.255793</td>\n",
              "      <td>0.093322</td>\n",
              "      <td>0.091639</td>\n",
              "      <td>0.120059</td>\n",
              "      <td>0.406666</td>\n",
              "      <td>0.071388</td>\n",
              "      <td>0.055277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ect</th>\n",
              "      <td>0.337249</td>\n",
              "      <td>0.375480</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.272863</td>\n",
              "      <td>0.369777</td>\n",
              "      <td>0.178028</td>\n",
              "      <td>0.400009</td>\n",
              "      <td>0.155783</td>\n",
              "      <td>0.974152</td>\n",
              "      <td>0.298387</td>\n",
              "      <td>...</td>\n",
              "      <td>0.134339</td>\n",
              "      <td>0.031431</td>\n",
              "      <td>0.046080</td>\n",
              "      <td>0.061550</td>\n",
              "      <td>0.004393</td>\n",
              "      <td>-0.007690</td>\n",
              "      <td>0.004368</td>\n",
              "      <td>0.141460</td>\n",
              "      <td>0.002492</td>\n",
              "      <td>-0.120782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>0.841200</td>\n",
              "      <td>0.825474</td>\n",
              "      <td>0.272863</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.751287</td>\n",
              "      <td>0.809665</td>\n",
              "      <td>0.815196</td>\n",
              "      <td>0.476764</td>\n",
              "      <td>0.235953</td>\n",
              "      <td>0.874276</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005151</td>\n",
              "      <td>0.104454</td>\n",
              "      <td>0.272963</td>\n",
              "      <td>0.253440</td>\n",
              "      <td>0.151980</td>\n",
              "      <td>0.084147</td>\n",
              "      <td>0.124766</td>\n",
              "      <td>0.400225</td>\n",
              "      <td>0.042484</td>\n",
              "      <td>0.114364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>for</th>\n",
              "      <td>0.784112</td>\n",
              "      <td>0.781971</td>\n",
              "      <td>0.369777</td>\n",
              "      <td>0.751287</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.681457</td>\n",
              "      <td>0.744098</td>\n",
              "      <td>0.495852</td>\n",
              "      <td>0.329051</td>\n",
              "      <td>0.762659</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022168</td>\n",
              "      <td>0.041775</td>\n",
              "      <td>0.236213</td>\n",
              "      <td>0.213631</td>\n",
              "      <td>0.134469</td>\n",
              "      <td>0.067151</td>\n",
              "      <td>0.121057</td>\n",
              "      <td>0.301074</td>\n",
              "      <td>0.038126</td>\n",
              "      <td>-0.003101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>military</th>\n",
              "      <td>0.129466</td>\n",
              "      <td>0.091639</td>\n",
              "      <td>-0.007690</td>\n",
              "      <td>0.084147</td>\n",
              "      <td>0.067151</td>\n",
              "      <td>0.073004</td>\n",
              "      <td>0.111685</td>\n",
              "      <td>0.006498</td>\n",
              "      <td>0.005429</td>\n",
              "      <td>0.120620</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002249</td>\n",
              "      <td>-0.002979</td>\n",
              "      <td>0.043408</td>\n",
              "      <td>0.104297</td>\n",
              "      <td>0.041300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.055227</td>\n",
              "      <td>0.049524</td>\n",
              "      <td>0.010835</td>\n",
              "      <td>0.064850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>allowing</th>\n",
              "      <td>0.127019</td>\n",
              "      <td>0.120059</td>\n",
              "      <td>0.004368</td>\n",
              "      <td>0.124766</td>\n",
              "      <td>0.121057</td>\n",
              "      <td>0.108786</td>\n",
              "      <td>0.105358</td>\n",
              "      <td>0.082757</td>\n",
              "      <td>-0.000966</td>\n",
              "      <td>0.138099</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002675</td>\n",
              "      <td>-0.003543</td>\n",
              "      <td>-0.005130</td>\n",
              "      <td>0.018550</td>\n",
              "      <td>0.276001</td>\n",
              "      <td>0.055227</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.096212</td>\n",
              "      <td>-0.003995</td>\n",
              "      <td>0.011279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ff</th>\n",
              "      <td>0.341878</td>\n",
              "      <td>0.406666</td>\n",
              "      <td>0.141460</td>\n",
              "      <td>0.400225</td>\n",
              "      <td>0.301074</td>\n",
              "      <td>0.444252</td>\n",
              "      <td>0.464473</td>\n",
              "      <td>0.195058</td>\n",
              "      <td>0.114210</td>\n",
              "      <td>0.448303</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005403</td>\n",
              "      <td>0.073690</td>\n",
              "      <td>0.130356</td>\n",
              "      <td>0.164296</td>\n",
              "      <td>0.114092</td>\n",
              "      <td>0.049524</td>\n",
              "      <td>0.096212</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.049690</td>\n",
              "      <td>0.135479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dry</th>\n",
              "      <td>0.051021</td>\n",
              "      <td>0.071388</td>\n",
              "      <td>0.002492</td>\n",
              "      <td>0.042484</td>\n",
              "      <td>0.038126</td>\n",
              "      <td>0.026403</td>\n",
              "      <td>0.093822</td>\n",
              "      <td>0.028883</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>0.077751</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003373</td>\n",
              "      <td>0.035028</td>\n",
              "      <td>-0.006468</td>\n",
              "      <td>0.018939</td>\n",
              "      <td>-0.003137</td>\n",
              "      <td>0.010835</td>\n",
              "      <td>-0.003995</td>\n",
              "      <td>0.049690</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.006260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Prediction</th>\n",
              "      <td>-0.004421</td>\n",
              "      <td>0.055277</td>\n",
              "      <td>-0.120782</td>\n",
              "      <td>0.114364</td>\n",
              "      <td>-0.003101</td>\n",
              "      <td>0.197234</td>\n",
              "      <td>0.107776</td>\n",
              "      <td>0.130293</td>\n",
              "      <td>-0.128340</td>\n",
              "      <td>0.154055</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.030375</td>\n",
              "      <td>-0.031694</td>\n",
              "      <td>0.098775</td>\n",
              "      <td>0.064315</td>\n",
              "      <td>0.038161</td>\n",
              "      <td>0.064850</td>\n",
              "      <td>0.011279</td>\n",
              "      <td>0.135479</td>\n",
              "      <td>-0.006260</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3001 rows × 3001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5494d683-52ca-4815-ab12-6dca3fb93d10')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5494d683-52ca-4815-ab12-6dca3fb93d10 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5494d683-52ca-4815-ab12-6dca3fb93d10');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop('Prediction', axis=1)\n",
        "y = df['Prediction']"
      ],
      "metadata": {
        "id": "zPzCWKvm1ygS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DBIBeuM3BBx",
        "outputId": "ee457c4b-0d3b-417a-e7f0-2c15d85e9752"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "5167    0\n",
              "5168    0\n",
              "5169    1\n",
              "5170    1\n",
              "5171    0\n",
              "Name: Prediction, Length: 5172, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)"
      ],
      "metadata": {
        "id": "DMIm-FBM3Bri"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = MultinomialNB()\n",
        "model2 = GaussianNB()\n",
        "model3 = SVC()\n",
        "\n"
      ],
      "metadata": {
        "id": "xbRsvChT3TmY"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "cGsBE9Jp7zdv",
        "outputId": "99bb1dcd-d760-4ae3-9daa-06656a0f9ab3"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "0qfwVFRy70-N",
        "outputId": "afc58009-73a6-4eef-c65c-075194401e86"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "KCr-Y6Qn72FW",
        "outputId": "d3ccda56-4097-4859-e36a-e5943ce9f9e6"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1 = model1.predict(x_test)\n",
        "y_pred2 = model2.predict(x_test)\n",
        "y_pred3 = model3.predict(x_test)\n",
        "\n",
        "print(f'model 1 :{accuracy_score(y_test, y_pred1)}', f'model 2 :{accuracy_score(y_test, y_pred2)}', f'model 3 :{accuracy_score(y_test, y_pred3)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdWYPK-c300l",
        "outputId": "2403c902-38e1-4c00-954c-36a2820d4bfc"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model 1 :0.9449275362318841 model 2 :0.9584541062801932 model 3 :0.7951690821256039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input"
      ],
      "metadata": {
        "id": "hUjjLQg3326s"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = Sequential()\n",
        "model4.add(Dense(480, activation='relu', input_shape=(3000, )))\n",
        "model4.add(Dense(120,activation = 'relu'))\n",
        "model4.add(Dense(84,activation = 'relu'))\n",
        "model4.add(Dense(2,activation = 'softmax'))\n",
        "# model4.add(Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "lTquPrOV8opq"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.compile(optimizer='sgd',loss=\"SparseCategoricalCrossentropy\",metrics=['accuracy']) \n",
        "results= model4.fit(x_train.values,y_train,epochs=50,batch_size=32, validation_data=(x_test.values, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfHzLwQr9HGr",
        "outputId": "d85003e2-f46e-4a27-857f-28432fff356b"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.5734 - accuracy: 0.8110 - val_loss: 0.6247 - val_accuracy: 0.7246\n",
            "Epoch 2/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.5122 - accuracy: 0.7547 - val_loss: 0.3425 - val_accuracy: 0.7903\n",
            "Epoch 3/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.7827 - val_loss: 0.2968 - val_accuracy: 0.8338\n",
            "Epoch 4/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8115 - val_loss: 0.6283 - val_accuracy: 0.7285\n",
            "Epoch 5/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.3538 - accuracy: 0.8453 - val_loss: 0.2887 - val_accuracy: 0.8696\n",
            "Epoch 6/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8642 - val_loss: 0.3197 - val_accuracy: 0.8425\n",
            "Epoch 7/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.2771 - accuracy: 0.8738 - val_loss: 0.2959 - val_accuracy: 0.8618\n",
            "Epoch 8/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.2718 - accuracy: 0.8830 - val_loss: 0.2587 - val_accuracy: 0.8850\n",
            "Epoch 9/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.2327 - accuracy: 0.8924 - val_loss: 0.3974 - val_accuracy: 0.8348\n",
            "Epoch 10/50\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.2681 - accuracy: 0.8888 - val_loss: 0.3645 - val_accuracy: 0.8638\n",
            "Epoch 11/50\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.2600 - accuracy: 0.8876 - val_loss: 0.2847 - val_accuracy: 0.8957\n",
            "Epoch 12/50\n",
            "130/130 [==============================] - 1s 10ms/step - loss: 0.2886 - accuracy: 0.8852 - val_loss: 0.5793 - val_accuracy: 0.8039\n",
            "Epoch 13/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.2332 - accuracy: 0.9067 - val_loss: 0.5124 - val_accuracy: 0.6174\n",
            "Epoch 14/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.2342 - accuracy: 0.8936 - val_loss: 0.2887 - val_accuracy: 0.8589\n",
            "Epoch 15/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.2520 - accuracy: 0.8915 - val_loss: 0.4092 - val_accuracy: 0.8686\n",
            "Epoch 16/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.4446 - accuracy: 0.8484 - val_loss: 0.3477 - val_accuracy: 0.8860\n",
            "Epoch 17/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.2907 - accuracy: 0.8779 - val_loss: 0.2003 - val_accuracy: 0.9111\n",
            "Epoch 18/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.2581 - accuracy: 0.8929 - val_loss: 0.3504 - val_accuracy: 0.8464\n",
            "Epoch 19/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.4231 - accuracy: 0.8293 - val_loss: 0.5162 - val_accuracy: 0.8628\n",
            "Epoch 20/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.3568 - accuracy: 0.8760 - val_loss: 0.2154 - val_accuracy: 0.9169\n",
            "Epoch 21/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.2271 - accuracy: 0.9043 - val_loss: 0.2364 - val_accuracy: 0.8657\n",
            "Epoch 22/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.2438 - accuracy: 0.9108 - val_loss: 0.2808 - val_accuracy: 0.8261\n",
            "Epoch 23/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.2627 - accuracy: 0.9074 - val_loss: 0.2471 - val_accuracy: 0.8937\n",
            "Epoch 24/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9152 - val_loss: 0.1965 - val_accuracy: 0.9198\n",
            "Epoch 25/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.3181 - accuracy: 0.8934 - val_loss: 0.2287 - val_accuracy: 0.9024\n",
            "Epoch 26/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.2164 - accuracy: 0.9200 - val_loss: 1.2557 - val_accuracy: 0.5961\n",
            "Epoch 27/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.2175 - accuracy: 0.9243 - val_loss: 0.2191 - val_accuracy: 0.9150\n",
            "Epoch 28/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.1937 - accuracy: 0.9246 - val_loss: 0.1989 - val_accuracy: 0.9198\n",
            "Epoch 29/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.1759 - accuracy: 0.9306 - val_loss: 0.2161 - val_accuracy: 0.9150\n",
            "Epoch 30/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.1784 - accuracy: 0.9294 - val_loss: 0.4209 - val_accuracy: 0.8937\n",
            "Epoch 31/50\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.1665 - accuracy: 0.9376 - val_loss: 0.2142 - val_accuracy: 0.9024\n",
            "Epoch 32/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.2695 - accuracy: 0.8920 - val_loss: 0.3730 - val_accuracy: 0.8995\n",
            "Epoch 33/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.2378 - accuracy: 0.9108 - val_loss: 0.4015 - val_accuracy: 0.8618\n",
            "Epoch 34/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.1547 - accuracy: 0.9410 - val_loss: 0.1841 - val_accuracy: 0.9256\n",
            "Epoch 35/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.2674 - accuracy: 0.8886 - val_loss: 0.7136 - val_accuracy: 0.3362\n",
            "Epoch 36/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.6022 - accuracy: 0.6623 - val_loss: 0.2931 - val_accuracy: 0.8889\n",
            "Epoch 37/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.2377 - accuracy: 0.9033 - val_loss: 0.1792 - val_accuracy: 0.9217\n",
            "Epoch 38/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.9110 - val_loss: 0.1672 - val_accuracy: 0.9208\n",
            "Epoch 39/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8985 - val_loss: 0.2558 - val_accuracy: 0.9179\n",
            "Epoch 40/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.2350 - accuracy: 0.9120 - val_loss: 0.2004 - val_accuracy: 0.9121\n",
            "Epoch 41/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.1929 - accuracy: 0.9258 - val_loss: 0.1907 - val_accuracy: 0.9140\n",
            "Epoch 42/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.1458 - accuracy: 0.9391 - val_loss: 0.1668 - val_accuracy: 0.9295\n",
            "Epoch 43/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9350 - val_loss: 0.1752 - val_accuracy: 0.9217\n",
            "Epoch 44/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.3526 - accuracy: 0.8847 - val_loss: 0.2470 - val_accuracy: 0.9092\n",
            "Epoch 45/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.2452 - accuracy: 0.9149 - val_loss: 0.1943 - val_accuracy: 0.9188\n",
            "Epoch 46/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.3164 - accuracy: 0.8813 - val_loss: 1.1334 - val_accuracy: 0.5362\n",
            "Epoch 47/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9299 - val_loss: 0.1698 - val_accuracy: 0.9275\n",
            "Epoch 48/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.1924 - accuracy: 0.9282 - val_loss: 0.2299 - val_accuracy: 0.9295\n",
            "Epoch 49/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.1669 - accuracy: 0.9410 - val_loss: 0.2042 - val_accuracy: 0.9188\n",
            "Epoch 50/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.1529 - accuracy: 0.9417 - val_loss: 0.1546 - val_accuracy: 0.9333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "3sDfsXP99Qe9"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_scale = scaler.fit_transform(x_train)\n",
        "x_test_scale = scaler.fit_transform(x_test)"
      ],
      "metadata": {
        "id": "bkSQFyMh94dn"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = Sequential()\n",
        "model5.add(Dense(480, activation='relu', input_shape=(3000, )))\n",
        "model5.add(Dense(120,activation = 'relu'))\n",
        "model5.add(Dense(84,activation = 'relu'))\n",
        "model5.add(Dense(2,activation = 'softmax'))\n",
        "# model4.add(Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "FWhC7QirB6XJ"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.compile(optimizer='sgd',loss=\"SparseCategoricalCrossentropy\",metrics=['accuracy']) \n",
        "results= model5.fit(x_train_scale,y_train,epochs=50,batch_size=32, validation_data=(x_test_scale, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYsHmHVbEQMH",
        "outputId": "c3fc1365-0ea3-4206-b36c-30d2690e92c2"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.6360 - accuracy: 0.6940 - val_loss: 0.5936 - val_accuracy: 0.7246\n",
            "Epoch 2/50\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 0.5948 - accuracy: 0.7066 - val_loss: 0.5754 - val_accuracy: 0.7275\n",
            "Epoch 3/50\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 0.5799 - accuracy: 0.7124 - val_loss: 0.5582 - val_accuracy: 0.7333\n",
            "Epoch 4/50\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.5606 - accuracy: 0.7230 - val_loss: 0.5358 - val_accuracy: 0.7411\n",
            "Epoch 5/50\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.5289 - accuracy: 0.7283 - val_loss: 0.4977 - val_accuracy: 0.7536\n",
            "Epoch 6/50\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 0.4807 - accuracy: 0.7501 - val_loss: 0.4416 - val_accuracy: 0.7758\n",
            "Epoch 7/50\n",
            "130/130 [==============================] - 1s 10ms/step - loss: 0.4161 - accuracy: 0.7928 - val_loss: 0.3739 - val_accuracy: 0.8367\n",
            "Epoch 8/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8509 - val_loss: 0.3038 - val_accuracy: 0.8754\n",
            "Epoch 9/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.2761 - accuracy: 0.8980 - val_loss: 0.2463 - val_accuracy: 0.9198\n",
            "Epoch 10/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.2208 - accuracy: 0.9350 - val_loss: 0.2005 - val_accuracy: 0.9382\n",
            "Epoch 11/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.9546 - val_loss: 0.1714 - val_accuracy: 0.9449\n",
            "Epoch 12/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.9679 - val_loss: 0.1489 - val_accuracy: 0.9575\n",
            "Epoch 13/50\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9756 - val_loss: 0.1353 - val_accuracy: 0.9585\n",
            "Epoch 14/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.1101 - accuracy: 0.9785 - val_loss: 0.1247 - val_accuracy: 0.9643\n",
            "Epoch 15/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.0975 - accuracy: 0.9814 - val_loss: 0.1169 - val_accuracy: 0.9633\n",
            "Epoch 16/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.0873 - accuracy: 0.9828 - val_loss: 0.1097 - val_accuracy: 0.9643\n",
            "Epoch 17/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9860 - val_loss: 0.1066 - val_accuracy: 0.9662\n",
            "Epoch 18/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.0718 - accuracy: 0.9884 - val_loss: 0.1028 - val_accuracy: 0.9671\n",
            "Epoch 19/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.0660 - accuracy: 0.9884 - val_loss: 0.0995 - val_accuracy: 0.9662\n",
            "Epoch 20/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.0611 - accuracy: 0.9891 - val_loss: 0.0964 - val_accuracy: 0.9691\n",
            "Epoch 21/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.0571 - accuracy: 0.9906 - val_loss: 0.0948 - val_accuracy: 0.9700\n",
            "Epoch 22/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9894 - val_loss: 0.0972 - val_accuracy: 0.9681\n",
            "Epoch 23/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9915 - val_loss: 0.0918 - val_accuracy: 0.9691\n",
            "Epoch 24/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9915 - val_loss: 0.0951 - val_accuracy: 0.9604\n",
            "Epoch 25/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.0438 - accuracy: 0.9913 - val_loss: 0.0903 - val_accuracy: 0.9729\n",
            "Epoch 26/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9927 - val_loss: 0.0889 - val_accuracy: 0.9700\n",
            "Epoch 27/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.0391 - accuracy: 0.9930 - val_loss: 0.0890 - val_accuracy: 0.9691\n",
            "Epoch 28/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.0373 - accuracy: 0.9942 - val_loss: 0.0888 - val_accuracy: 0.9739\n",
            "Epoch 29/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.0355 - accuracy: 0.9942 - val_loss: 0.0893 - val_accuracy: 0.9700\n",
            "Epoch 30/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.0338 - accuracy: 0.9952 - val_loss: 0.0906 - val_accuracy: 0.9681\n",
            "Epoch 31/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.0324 - accuracy: 0.9952 - val_loss: 0.0922 - val_accuracy: 0.9691\n",
            "Epoch 32/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9949 - val_loss: 0.0903 - val_accuracy: 0.9691\n",
            "Epoch 33/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9947 - val_loss: 0.0920 - val_accuracy: 0.9700\n",
            "Epoch 34/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9947 - val_loss: 0.0890 - val_accuracy: 0.9691\n",
            "Epoch 35/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9954 - val_loss: 0.0894 - val_accuracy: 0.9700\n",
            "Epoch 36/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9949 - val_loss: 0.0895 - val_accuracy: 0.9710\n",
            "Epoch 37/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9956 - val_loss: 0.0906 - val_accuracy: 0.9710\n",
            "Epoch 38/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9966 - val_loss: 0.0900 - val_accuracy: 0.9720\n",
            "Epoch 39/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9956 - val_loss: 0.0900 - val_accuracy: 0.9710\n",
            "Epoch 40/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.9954 - val_loss: 0.0924 - val_accuracy: 0.9681\n",
            "Epoch 41/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9954 - val_loss: 0.0903 - val_accuracy: 0.9710\n",
            "Epoch 42/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9961 - val_loss: 0.0910 - val_accuracy: 0.9710\n",
            "Epoch 43/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9961 - val_loss: 0.0922 - val_accuracy: 0.9700\n",
            "Epoch 44/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9964 - val_loss: 0.0918 - val_accuracy: 0.9720\n",
            "Epoch 45/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9971 - val_loss: 0.0926 - val_accuracy: 0.9739\n",
            "Epoch 46/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9959 - val_loss: 0.0925 - val_accuracy: 0.9720\n",
            "Epoch 47/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9959 - val_loss: 0.0925 - val_accuracy: 0.9720\n",
            "Epoch 48/50\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9964 - val_loss: 0.0933 - val_accuracy: 0.9739\n",
            "Epoch 49/50\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 0.0937 - val_accuracy: 0.9710\n",
            "Epoch 50/50\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 0.0182 - accuracy: 0.9971 - val_loss: 0.0947 - val_accuracy: 0.9700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "npdarRNQEW5j"
      },
      "execution_count": 110,
      "outputs": []
    }
  ]
}